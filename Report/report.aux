\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{CNN}
\citation{CNN}
\bibcite{CNN}{1}
\HyPL@Entry{0<</S/D>>}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:AccCNN1}{{1a}{1}{Batch size 1.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:AccCNN1}{{a}{1}{Batch size 1.\relax }{figure.caption.1}{}}
\newlabel{fig:AccCNN128}{{1b}{1}{Batch size 128.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:AccCNN128}{{b}{1}{Batch size 128.\relax }{figure.caption.1}{}}
\newlabel{fig:AccCNN1024}{{1c}{1}{Batch size 1024.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:AccCNN1024}{{c}{1}{Batch size 1024.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The accuracy for the train and test set for each epoch for the simplified CNN network. Batch size as in subcaption.\relax }}{1}{figure.caption.1}\protected@file@percent }
\newlabel{fig:AccCNN}{{1}{1}{The accuracy for the train and test set for each epoch for the simplified CNN network. Batch size as in subcaption.\relax }{figure.caption.1}{}}
\citation{auto}
\bibcite{auto}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The input and the output of the autoencoder. The loss of this autoencoder is 0.10 so we lose quite a lot of information.\relax }}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:auto}{{1}{2}{The input and the output of the autoencoder. The loss of this autoencoder is 0.10 so we lose quite a lot of information.\relax }{figure.caption.3}{}}
\citation{RNN}
\bibcite{RNN}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Accuracy vs. the number of epochs for the addition problem.\relax }}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:AccuracyRNN}{{1}{3}{Accuracy vs. the number of epochs for the addition problem.\relax }{figure.caption.5}{}}
\citation{onsager}
\citation{onsager}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Background}{4}{section.2}\protected@file@percent }
\citation{RG}
\citation{RG}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 2D Ising configurations at three temperatures below, around and above the critical temperature respectively. System size of $64 \times 64$ spins. Below the critical temperature all the spins are aligned, above the critical temperature the spins are random which results in zero net spin. \relax }}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:lattices}{{1}{5}{2D Ising configurations at three temperatures below, around and above the critical temperature respectively. System size of $64 \times 64$ spins. Below the critical temperature all the spins are aligned, above the critical temperature the spins are random which results in zero net spin. \relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of a transformation used in Renormalization Group theory applied to the 2d square lattice Ising model. The technical details not relevant. The RG transformation resembles the effect a convolutional filter has on an image. Source: \cite  {RG} \relax }}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:RG}{{2}{5}{Example of a transformation used in Renormalization Group theory applied to the 2d square lattice Ising model. The technical details not relevant. The RG transformation resembles the effect a convolutional filter has on an image. Source: \cite {RG} \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{5}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameters used to generate the dataset using MCMC. \relax }}{6}{table.caption.9}\protected@file@percent }
\newlabel{tab:params}{{1}{6}{Parameters used to generate the dataset using MCMC. \relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The average magnetisation per spin for the generated data points generated using the parameters as given in table \ref  {tab:params}. One can see there is a clear transition happening around the analytical value of $T_C$. \relax }}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:mags}{{3}{6}{The average magnetisation per spin for the generated data points generated using the parameters as given in table \ref {tab:params}. One can see there is a clear transition happening around the analytical value of $T_C$. \relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameters used for the Convolutional layer. \relax }}{6}{table.caption.11}\protected@file@percent }
\newlabel{tab:CNNparam}{{2}{6}{Parameters used for the Convolutional layer. \relax }{table.caption.11}{}}
\citation{phasemethod}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The weight matrix for the final fully connected layer after 300 epochs. The x axis corresponds with the final classes. Around the 25th class there is a phase transistion from dark to random noise. This 25th class coresponds to $\beta = \pm 0.45$ \relax }}{7}{figure.caption.12}\protected@file@percent }
\newlabel{fig:weights}{{4}{7}{The weight matrix for the final fully connected layer after 300 epochs. The x axis corresponds with the final classes. Around the 25th class there is a phase transistion from dark to random noise. This 25th class coresponds to $\beta = \pm 0.45$ \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The sums of the weights after 300 epochs for each class of the inverse temperature for the weights in figure \ref  {fig:weights} with a fitted $\qopname  \relax o{tanh}$ function to find the critical inverse temperature at $\beta _C = 0.449(9)$. \relax }}{7}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fit}{{5}{7}{The sums of the weights after 300 epochs for each class of the inverse temperature for the weights in figure \ref {fig:weights} with a fitted $\tanh $ function to find the critical inverse temperature at $\beta _C = 0.449(9)$. \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The sums of the weights after 1000 epochs for each class of the inverse temperature for the weights in figure \ref  {fig:weightswrong} with a fitted $\qopname  \relax o{tanh}$ function where we can see that the fit does not fit the data properly. \relax }}{8}{figure.caption.14}\protected@file@percent }
\newlabel{fig:fitwrong}{{6}{8}{The sums of the weights after 1000 epochs for each class of the inverse temperature for the weights in figure \ref {fig:weightswrong} with a fitted $\tanh $ function where we can see that the fit does not fit the data properly. \relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The weight matrix for the final fully connected layer after 1000 epochs. The x axis corresponds with the final classes. The transistion that was visible in figure \ref  {fig:weights} after 300 epochs has become less clear. \relax }}{8}{figure.caption.15}\protected@file@percent }
\newlabel{fig:weightswrong}{{7}{8}{The weight matrix for the final fully connected layer after 1000 epochs. The x axis corresponds with the final classes. The transistion that was visible in figure \ref {fig:weights} after 300 epochs has become less clear. \relax }{figure.caption.15}{}}
\bibcite{onsager}{1}
\bibcite{RG}{2}
\bibcite{phasemethod}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The estimate for the critical inverse temperature vs. the number of epochs. After around 500 epochs the phase transistion in the weights becomes less clear and therefore the estimate of the critical temperature deviates further from the analytical result represented by the black line. \relax }}{9}{figure.caption.16}\protected@file@percent }
\newlabel{fig:epochs}{{8}{9}{The estimate for the critical inverse temperature vs. the number of epochs. After around 500 epochs the phase transistion in the weights becomes less clear and therefore the estimate of the critical temperature deviates further from the analytical result represented by the black line. \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{9}{section.4}\protected@file@percent }
\gdef \@abspage@last{9}
